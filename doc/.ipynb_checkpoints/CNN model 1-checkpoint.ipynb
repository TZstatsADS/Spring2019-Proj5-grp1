{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, ConvLSTM2D, Conv3D, MaxPooling2D, Dropout, \\\n",
    "    MaxPooling3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "import json\n",
    "\n",
    "from EmoPy.src.callback import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _FERNeuralNet(object):\n",
    "    \"\"\"\n",
    "    Interface for all FER deep neural net classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emotion_map):\n",
    "        self.emotion_map = emotion_map\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        raise NotImplementedError(\"Class %s doesn't implement _init_model()\" % self.__class__.__name__)\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        raise NotImplementedError(\"Class %s doesn't implement fit()\" % self.__class__.__name__)\n",
    "\n",
    "    def fit_generator(self, generator, validation_data=None, epochs=50):\n",
    "        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
    "        self.model.fit_generator(generator=generator, validation_data=validation_data, epochs=epochs,\n",
    "                                 callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3), PlotLosses()])\n",
    "\n",
    "    def predict(self, images):\n",
    "        self.model.predict(images)\n",
    "\n",
    "    def save_model_graph(self):\n",
    "        plot_model(self.model, to_file='output/model.png')\n",
    "\n",
    "    def export_model(self, model_filepath, weights_filepath, emotion_map_filepath, emotion_map):\n",
    "        self.model.save_weights(weights_filepath)\n",
    "\n",
    "        model_json_string = self.model.to_json()\n",
    "        model_json_file = open(model_filepath, 'w')\n",
    "        model_json_file.write(model_json_string)\n",
    "        model_json_file.close()\n",
    "\n",
    "        with open(emotion_map_filepath, 'w') as fp:\n",
    "            json.dump(emotion_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNN(_FERNeuralNet):\n",
    "    \"\"\"\n",
    "    2D Convolutional Neural Network\n",
    "    :param image_size: dimensions of input images\n",
    "    :param channels: number of image channels\n",
    "    :param emotion_map: dict of target emotion label keys with int values corresponding to the index of the emotion probability in the prediction output array\n",
    "    :param filters: number of filters/nodes per layer in CNN\n",
    "    :param kernel_size: size of sliding window for each layer of CNN\n",
    "    :param activation: name of activation function for CNN\n",
    "    :param verbose: if true, will print out extra process information\n",
    "    **Example**::\n",
    "        net = ConvolutionalNN(target_dimensions=(64,64), channels=1, target_labels=[0,1,2,3,4,5,6], time_delay=3)\n",
    "        net.fit(features, labels, validation_split=0.15)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size, channels, emotion_map, filters=10, kernel_size=(4, 4), activation='relu',\n",
    "                 verbose=False):\n",
    "        #we define what kind of self we want, image that self = person, and image_size can be name, channels can be age```\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        super().__init__(emotion_map)\n",
    "\n",
    "    def _init_model(self):\n",
    "        \"\"\"\n",
    "        Composes all layers of 2D CNN.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        # Sequential() is a model in Keras which is a linear stack of layers\n",
    "        model.add(Conv2D(input_shape=list(self.image_size) + [self.channels], filters=self.filters,\n",
    "                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
    "        #input指的是需要做卷积的输入图像，其具体含义是图片高度 图片宽度 图像管道数\n",
    "        #filter 为卷积核，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同\n",
    "        # specifying the width and height of the 2D convolution window. K kernels waiting to be applied to the image, each kernel is convolved with input volumn and the output of each convolution \n",
    "        #operation produces a 2D output,called activation map\n",
    "        #activation 函数 为relu，增加non-linear性\n",
    "        #channels last = 输入个个维度的顺序，channel lasy对应：batch，steps，channels\n",
    "        #This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "        #The image shows the differences in size of each of the network layers.\n",
    "        #Convolutional layers apply a convolution operation to the input, passing the result to the next layer\n",
    "        #The convolution emulates the response of an individual neuron to visual stimuli.\n",
    "        #Pooling layers are used to reduce the input space and thus complexity and processing time.\n",
    "        #The flattening layer converts the output of the previous layer to a one-dimensional vector,\n",
    "        #and the final layer takes that vector and calculates a final classification output.\n",
    "        model.add(\n",
    "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(\n",
    "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
    "        model.add(\n",
    "            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"relu\"))\n",
    "        if self.verbose:\n",
    "            model.summary()\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, image_data, labels, validation_split, epochs=50):\n",
    "        \"\"\"\n",
    "        Trains the neural net on the data provided.\n",
    "        :param image_data: Numpy array of training data.\n",
    "        :param labels: Numpy array of target (label) data.\n",
    "        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n",
    "        :param batch_size:\n",
    "        :param epochs: number of times to train over input dataset.\n",
    "        \"\"\"\n",
    "        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n",
    "        self.model.fit(image_data, labels, epochs=epochs, validation_split=validation_split,\n",
    "                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianchenwang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from EmoPy.src.fermodel import FERModel\n",
    "from EmoPy.src.directory_data_loader import DirectoryDataLoader\n",
    "from EmoPy.src.data_generator import DataGenerator\n",
    "from pkg_resources import resource_filename,resource_exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from EmoPy.src.csv_data_loader import CSVDataLoader\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Convolutional Model -------------------\n",
      "Loading data...\n",
      "\n",
      "DATASET DETAILS\n",
      "18 image samples\n",
      "15 training samples\n",
      "3 test samples\n",
      "\n",
      "Preparing training/testing data...\n",
      "Training net...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianchenwang/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:138: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ret = um.sqrt(ret, out=ret)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 61, 61, 10)        170       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 58, 58, 10)        1610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 58, 29, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 55, 26, 10)        810       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 52, 23, 10)        1610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 52, 11, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2860)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 8583      \n",
      "=================================================================\n",
      "Total params: 12,783\n",
      "Trainable params: 12,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 480ms/step - loss: -0.3994 - acc: 0.2667 - val_loss: -0.3157 - val_acc: 0.3333\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: -0.4202 - acc: 0.2667 - val_loss: -0.5299 - val_acc: 0.3333\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: -0.3892 - acc: 0.2667 - val_loss: -0.6450 - val_acc: 0.6667\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: -0.4628 - acc: 0.4000 - val_loss: -0.7832 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: -0.4367 - acc: 0.2667 - val_loss: -0.2510 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.15\n",
    "\n",
    "target_dimensions = (64, 64)\n",
    "channels = 1\n",
    "verbose = True\n",
    "\n",
    "print('--------------- Convolutional Model -------------------')\n",
    "print('Loading data...')\n",
    "directory_path = resource_filename('EmoPy.examples','image_data/sample_image_directory')\n",
    "data_loader = DirectoryDataLoader(datapath=directory_path, validation_split=validation_split)\n",
    "dataset = data_loader.load_data()\n",
    "\n",
    "if verbose:\n",
    "    dataset.print_data_details()\n",
    "\n",
    "print('Preparing training/testing data...')\n",
    "train_images, train_labels = dataset.get_training_data()\n",
    "train_gen = DataGenerator().fit(train_images, train_labels)\n",
    "test_images, test_labels = dataset.get_test_data()\n",
    "test_gen = DataGenerator().fit(test_images, test_labels)\n",
    "\n",
    "print('Training net...')\n",
    "model = ConvolutionalNN(target_dimensions, filter = 50, kernel_size=(2,2), channels, dataset.get_emotion_index_map(), verbose=True)\n",
    "model.fit_generator(train_gen.generate(target_dimensions, batch_size=5),\n",
    "                    test_gen.generate(target_dimensions, batch_size=5),\n",
    "                    epochs=5)\n",
    "\n",
    "# Save model configuration\n",
    "# model.export_model('output/conv2d_model.json','output/conv2d_weights.h5',\"output/conv2d_emotion_map.json\", emotion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 490, 640, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training data from csv...\n"
     ]
    }
   ],
   "source": [
    "# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "raw_dimensions = (48, 48)\n",
    "target_dimensions = (64, 64)\n",
    "verbose = True\n",
    "channels = 3\n",
    "\n",
    "emotion_map = {'0':'Angry',\n",
    "              '1':'Disgust',\n",
    "              '2':'Fear',\n",
    "              '3':'Happy',\n",
    "              '4':'Sad',\n",
    "              '5':'Surprise',\n",
    "              '6':'Neutral'}\n",
    "data_loader = CSVDataLoader(emotion_map, datapath='../data/fer2013.csv',\n",
    "                            image_dimensions=raw_dimensions, \n",
    "                            csv_label_col=0, csv_image_col=1, out_channels=3)\n",
    "\n",
    "dataset = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET DETAILS\n",
      "35887 image samples\n",
      "28709 training samples\n",
      "7178 test samples\n",
      "\n",
      "Creating training/testing data...\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    dataset.print_data_details()\n",
    "\n",
    "print('Creating training/testing data...')\n",
    "train_images, train_labels = dataset.get_training_data()\n",
    "train_gen = DataGenerator().fit(train_images, train_labels)\n",
    "test_images, test_labels = dataset.get_test_data()\n",
    "test_gen = DataGenerator().fit(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training model CNNLSTM\n",
    "# from EmoPy.src.neuralnets import ConvolutionalLstmNN\n",
    "\n",
    "# start = time.time()\n",
    "# model = ConvolutionalLstmNN(target_dimensions, channels, \n",
    "#                             dataset.get_emotion_index_map(), verbose=True)\n",
    "\n",
    "# model.fit_generator(train_gen.generate(target_dimensions, batch_size=5),\n",
    "#                     test_gen.generate(target_dimensions, batch_size=5),\n",
    "#                     epochs=5)\n",
    "\n",
    "# end = time.time()\n",
    "# print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 61, 61, 10)        490       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 58, 58, 10)        1610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 58, 29, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 55, 26, 10)        810       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 52, 23, 10)        1610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 52, 11, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2860)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 20027     \n",
      "=================================================================\n",
      "Total params: 24,547\n",
      "Trainable params: 24,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5742/5742 [==============================] - 480s 84ms/step - loss: -0.3667 - acc: 0.2457 - val_loss: -0.3700 - val_acc: 0.2515\n",
      "Epoch 2/5\n",
      " 923/5742 [===>..........................] - ETA: 6:01 - loss: -0.3704 - acc: 0.2459"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d7305a2928de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit_generator(train_gen.generate(target_dimensions, batch_size=5),\n\u001b[1;32m      7\u001b[0m                     \u001b[0mtest_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     epochs=5)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/EmoPy/src/neuralnets.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, validation_data, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RMSProp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cosine_proximity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         self.model.fit_generator(generator=generator, validation_data=validation_data, epochs=epochs,\n\u001b[0;32m---> 35\u001b[0;31m                                  callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3), PlotLosses()])\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from EmoPy.src.neuralnets import ConvolutionalNN\n",
    "\n",
    "# training model CNN\n",
    "start = time.time()\n",
    "model = ConvolutionalNN(target_dimensions, channels, dataset.get_emotion_index_map(), verbose=True)\n",
    "model.fit_generator(train_gen.generate(target_dimensions, batch_size=5),\n",
    "                    test_gen.generate(target_dimensions, batch_size=5),\n",
    "                    epochs=5)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EmoPy.src.data_generator.DataGenerator at 0x1a3734f470>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
